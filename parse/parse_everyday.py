import asyncio
import multiprocessing
from typing import List, Dict, Callable

import os
import psutil
import shutil
import subprocess

from config import logger
from database.events_db import add_events, add_descriptions, get_events_without_description, \
    move_events_from_temp_to_release_table
from parse.ticketland.parse_events import get_all_events_ticketland
from parse.afisharu.parse_events import get_all_events_afisharu
from parse.afisharu.parse_description_of_events import get_event_description_afisharu
from parse.ticketland.parse_description_of_events import get_event_descriptions_ticketland
from parse.yandex_afisha.parse_events import get_all_events_yandex_afisha
from parse.yandex_afisha.parse_description_of_events import get_event_description_yandex_afisha


def run_parallel(func: Callable, urls: List[str], num_processes: int = 2) -> Dict[str, str]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
    """
    chunk_size = max(1, len(urls) // num_processes)  # –†–∞–∑–±–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ –Ω–∞ —á–∞—Å—Ç–∏
    url_chunks = [urls[i:i + chunk_size] for i in range(0, len(urls), chunk_size)]

    logger.info(f"üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º {num_processes} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤, –∫–∞–∂–¥–∞—è —á–∞—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç {chunk_size} —Å—Å—ã–ª–æ–∫...")

    with multiprocessing.Pool(processes=num_processes) as pool:
        results = pool.starmap(func, [(i, chunk) for i, chunk in enumerate(url_chunks)])

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –≤ –æ–¥–∏–Ω —Å–ª–æ–≤–∞—Ä—å
    merged_results = {}
    for result in results:
        if result:
            merged_results.update(result)

    return merged_results


async def parse_everyday_ticketland():
    all_events_list_of_dicts = get_all_events_ticketland()
    if all_events_list_of_dicts is not None:
        await add_events(all_events_list_of_dicts)

    list_of_records = await get_events_without_description()
    list_of_links = [record['link'] for record in list_of_records]

    if list_of_links is not None:
        description = run_parallel(get_event_descriptions_ticketland, list_of_links)
        await add_descriptions(description)

    await asyncio.to_thread(clean_up)

    await move_events_from_temp_to_release_table()

async def parse_everyday_afisharu():
    all_events_list_of_dicts = get_all_events_afisharu()
    if all_events_list_of_dicts is not None:
        await add_events(all_events_list_of_dicts)

    list_of_records = await get_events_without_description()
    list_of_links = [record['link'] for record in list_of_records]

    if list_of_links is not None:
        description = run_parallel(get_event_description_afisharu, list_of_links)
        await add_descriptions(description)

    await asyncio.to_thread(clean_up)

    await move_events_from_temp_to_release_table()

async def parse_everyday_yandex_afisha():
    all_events_list_of_dicts = get_all_events_yandex_afisha()
    if all_events_list_of_dicts is not None:
        await add_events(all_events_list_of_dicts)
    #
    # list_of_records = await get_events_without_description()
    # list_of_links = [record['link'] for record in list_of_records]
    #
    # if list_of_links is not None:
    #     # description = run_parallel(get_event_description_yandex_afisha, list_of_links)
    #     description = get_event_description_yandex_afisha(list_of_links)
    #     await add_descriptions(description)

    await asyncio.to_thread(clean_up)

    # await move_events_from_temp_to_release_table()

def clean_up():
    logger.info("üîÑ –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤...")

    # –ó–∞–∫—Ä—ã–≤–∞–µ–º Chrome –∏ Chromedriver
    subprocess.call("pkill -f chrome", shell=True)
    subprocess.call("pkill -f chromedriver", shell=True)

    # –û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞
    subprocess.call("sync; echo 3 > /proc/sys/vm/drop_caches", shell=True)

    # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    tmp_dirs = ["/tmp", "/dev/shm"]
    for d in tmp_dirs:
        try:
            shutil.rmtree(d, ignore_errors=True)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {d}: {e}")

    # –£–¥–∞–ª–µ–Ω–∏–µ –∑–æ–º–±–∏-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤
    for proc in psutil.process_iter():
        try:
            if proc.status() == psutil.STATUS_ZOMBIE:
                proc.kill()
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass

    logger.info('‚úÖ –ü–∞–º—è—Ç—å —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω–∞')

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ /tmp, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs("/tmp", exist_ok=True)

    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∞–≤ 1777 (drwxrwxrwt ‚Äî —á—Ç–µ–Ω–∏–µ, –∑–∞–ø–∏—Å—å –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö, –Ω–æ —É–¥–∞–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª—å—Ü–µ–º)
    os.chmod("/tmp", 0o1777)

    logger.info("–ü–∞–ø–∫–∞ /tmp —Å–æ–∑–¥–∞–Ω–∞ –∏ –ø—Ä–∞–≤–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –Ω–∞ 1777.")


if __name__ == "__main__":
    asyncio.run(parse_everyday_afisharu())